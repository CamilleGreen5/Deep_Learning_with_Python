{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Noise_speech_reduction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOAt18W26pdrG4j7aJMCerI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "94e6fdeca98a4d0b8c7ce52e6162ecd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_774c0af238a24314b0257646698fe490",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_96a124720fdb42a3a7e025a3329d440a",
              "IPY_MODEL_4df34abfa3eb41c5981bbd460670739a"
            ]
          }
        },
        "774c0af238a24314b0257646698fe490": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "96a124720fdb42a3a7e025a3329d440a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1918b54b8e624da485e46afc32cff7f2",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_37ae2d8f98424c71951abecbdb32617e"
          }
        },
        "4df34abfa3eb41c5981bbd460670739a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_627ed32a482a4a5dac594dcb0e61186e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/1 [03:10&lt;00:00, 190.56s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cb367e16a13a4bda87e91a76d8100782"
          }
        },
        "1918b54b8e624da485e46afc32cff7f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "37ae2d8f98424c71951abecbdb32617e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "627ed32a482a4a5dac594dcb0e61186e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cb367e16a13a4bda87e91a76d8100782": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CamilleGreen5/Deep_Learning_with_Python/blob/master/Noise_speech_reduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njrINNDksie4",
        "colab_type": "text"
      },
      "source": [
        "INFO :\n",
        "- methode des masks donnent mauvais résultats (avec label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5NDwppQei-Q",
        "colab_type": "text"
      },
      "source": [
        "## **DATA LOADING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfXnXSBj-05D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install pydub"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBv1yBnhcFAr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !rm -r test_data\n",
        "# !rm -r train_data\n",
        "# !rm -r val_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzPdSF9gRJcb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !wget https://voice-prod-bundler-ee1969a6ce8178826482b88e843c335139bd3fb4.s3.amazonaws.com/cv-corpus-5.1-2020-06-22/fr.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-mU_v6bWlRX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !tar -xf fr.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITu5Puvoakzl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !rm fr.tar.gz\n",
        "# !rm -r sample_data\n",
        "\n",
        "# !mkdir sons\n",
        "# !mkdir sons/original\n",
        "# !mkdir sons/noisy\n",
        "# !mkdir sons/denoised\n",
        "\n",
        "# !mkdir data\n",
        "# !mkdir data/train_data\n",
        "# !mkdir data/val_data\n",
        "# !mkdir data/test_data\n",
        "# !mkdir data/train_data/folder1\n",
        "# !mkdir data/val_data/folder1\n",
        "# !mkdir data/test_data/folder1\n",
        "\n",
        "# !cp cv-corpus-5.1-2020-06-22/fr/clips/common_voice_fr_18157595.mp3 ./sons/original"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9S0MO3jee8d",
        "colab_type": "text"
      },
      "source": [
        "## **FUNCTIONS AND LIBRARIES LOAD**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buYbi1H55f_3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%reload_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7GhHp8oNRF9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import datetime\n",
        "import os\n",
        "import cv2 as cv\n",
        "from scipy.io.wavfile import read, write\n",
        "from scipy.signal import stft, istft\n",
        "from pydub import AudioSegment\n",
        "from tensorflow.keras import models, layers\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hydHLwi8eyw5",
        "colab_type": "text"
      },
      "source": [
        "## **DATA CONVERSION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xuGp7mgCO7_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for path_to_mp3_file in tqdm(list_mp3_files[:1000]):\n",
        "\n",
        "#     # load mp3 sound to array\n",
        "#     loaded_sound = AudioSegment.from_mp3(path_to_mp3_file)\n",
        "#     array_sound = np.array(loaded_sound.get_array_of_samples(), np.uint16)\n",
        "#     max = 0\n",
        "#     if np.max(array_sound)>max:\n",
        "#         max=np.max(array_sound)\n",
        "# print(max) #(65535)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOdsq0ea13dj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_noise(array_sound):\n",
        "          \n",
        "    max_1 = np.max(array_sound)\n",
        "    noise = np.random.normal(0, 0.5*max_1, len(array_sound))\n",
        "    array_sound_noisy = np.add(noise, array_sound)\n",
        "    max_2 = np.max(array_sound_noisy)\n",
        "    array_sound_noisy = (array_sound_noisy*max_1)//max_2\n",
        "\n",
        "    return np.array(array_sound_noisy, np.uint16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2TT4gVTf4sK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_and_convert_data_with_label(train_mp3_data, mode='train'):\n",
        "\n",
        "    i = 0\n",
        "\n",
        "    for path_to_mp3_file in tqdm(train_mp3_data):\n",
        "\n",
        "        # load mp3 sound to array\n",
        "        loaded_sound = AudioSegment.from_mp3(path_to_mp3_file)\n",
        "        array_sound = np.array(loaded_sound.get_array_of_samples(), np.uint16)\n",
        "        # print(np.max(np.max(array_sound)))\n",
        "        \n",
        "        # normalize array\n",
        "        mean = np.mean(array_sound, axis=0)\n",
        "        array_sound -= int(mean)\n",
        "\n",
        "        # convert label to to F_T_space\n",
        "        f, t, array_stft = stft(array_sound, fs=48000, nperseg=1000)\n",
        "        original_abs_stft = np.abs(array_stft[:2000])\n",
        "\n",
        "        # padding \n",
        "        pad_length = 1000 - np.shape(original_abs_stft)[1]\n",
        "        original_abs_stft = np.pad(original_abs_stft, ((0,0), (0, pad_length)))\n",
        "\n",
        "        # add random noise\n",
        "        array_sound_noisy = add_noise(array_sound)\n",
        "\n",
        "        # convert sample to to F_T_space\n",
        "        f, t, array_stft = stft(array_sound_noisy, fs=48000, nperseg=1000)\n",
        "        sample_abs_stft = np.abs(array_stft)\n",
        "\n",
        "        # padding \n",
        "        pad_length = 1000 - np.shape(sample_abs_stft)[1]\n",
        "        sample_abs_stft = np.pad(sample_abs_stft, ((0,0), (0, pad_length)))\n",
        "        # print(np.shape(sample_abs_stft))\n",
        "\n",
        "        # convertion to image format\n",
        "        sample_to_save = np.where(sample_to_save < 65024, sample_to_save, 65024)\n",
        "        sample_to_save0 = sample_to_save - sample_to_save%1000\n",
        "        sample_to_save1 = sample_to_save - sample_to_save0 - sample_to_save%10\n",
        "        label_to_save0 = label_to_save - label_to_save%1000\n",
        "        label_to_save1 = label_to_save - label_to_save0 - label_to_save%10\n",
        "        sample_label_to_save = np.stack((sample_to_save0, sample_to_save1, label_to_save0, label_to_save1), axis=2)\n",
        "        sample_label_to_save = np.array(sample_label_to_save, np.int16)\n",
        "        print(np.shape(sample_label_to_save))\n",
        "\n",
        "        # saving images\n",
        "        if mode == 'train':\n",
        "            path_sample = str(\"./data/train_data/folder1/sample\" + str(i) + \".png\")\n",
        "        elif mode == 'val':\n",
        "            path_sample = str(\"./data/val_data/folder1/sample\" + str(i) + \".png\")\n",
        "        elif mode == 'test':\n",
        "            path_sample = str(\"./data/test_data/folder1/sample\" + str(i) + \".png\")\n",
        "        else:\n",
        "            print(\"chose a mode\")\n",
        "        tf.keras.preprocessing.image.save_img(path_sample, sample_label_to_save, data_format='channels_last')\n",
        "\n",
        "        # free space\n",
        "        path = train_mp3_data[i]\n",
        "        try:\n",
        "            os.remove(path)\n",
        "        except FileNotFoundError:\n",
        "            continue\n",
        "\n",
        "        i+=1\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOvohzPDeb9U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4c98156f-6415-43cb-8890-08c05bb8795c"
      },
      "source": [
        "list_mp3_files = glob.glob(\"./cv-corpus-5.1-2020-06-22/fr/clips/*.mp3\")\n",
        "print(len(list_mp3_files))\n",
        "\n",
        "train_mp3_data = list_mp3_files[:1]\n",
        "val_mp3_data = list_mp3_files[1:2]\n",
        "# test_mp3_data = list_mp3_files[7000:14000]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "450064\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCwxQ3Z6j-FI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "load_and_convert_data_with_label(train_mp3_data, 'train')\n",
        "load_and_convert_data_with_label(val_mp3_data, 'val')\n",
        "# load_and_convert_data_with_label(test_mp3_data, 'test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DSWHdQaFr7U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls train_data/folder1 | wc -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsBC7dTbfCcD",
        "colab_type": "text"
      },
      "source": [
        "## **MODEL FITING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0f500K0Izlr6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !rm -r logs/fit/*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5YPnEf4AS7m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model():\n",
        "\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Dense(1000, activation='relu', input_shape=(501,)))\n",
        "    model.add(layers.Dense(1000, activation='relu'))\n",
        "    model.add(layers.Dense(1000, activation='relu'))\n",
        "    # regulizer, lstm ?\n",
        "    model.add(layers.Dense(501))\n",
        "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7JeMASisCLN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_generator(mode='train'):\n",
        "\n",
        "    img_gen = tf.keras.preprocessing.image.ImageDataGenerator()\n",
        "    if mode == 'train':\n",
        "        samples_and_labels = img_gen.flow_from_directory(\"./data/train_data/\", class_mode=None, target_size=(501, 1000), batch_size=1, color_mode='rgba')\n",
        "    elif mode == 'val':\n",
        "        samples_and_labels = img_gen.flow_from_directory(\"./data/val_data/\", class_mode=None, target_size=(501, 1000), batch_size=1, color_mode='rgba')\n",
        "    elif mode == 'test':\n",
        "        samples_and_labels = img_gen.flow_from_directory(\"./data/test_data/\", class_mode=None, target_size=(501, 1000), batch_size=1, color_mode='rgba')  \n",
        "    else:\n",
        "        print(\"chose a mode\")\n",
        "\n",
        "    for sample_and_label in samples_and_labels:\n",
        "        sample_and_label = np.array(sample_and_label, np.int16)\n",
        "        # print(np.shape(sample_and_label))\n",
        "        sample0 = np.squeeze(sample_and_label[:,:,:,0])\n",
        "        sample1 = np.squeeze(sample_and_label[:,:,:,1])\n",
        "        label0 = np.squeeze(sample_and_label[:,:,:,2])\n",
        "        label1 = np.squeeze(sample_and_label[:,:,:,3])\n",
        "        sample = 1000*sample0 + 10*sample1\n",
        "        label1 = 1000*label0 + 10*label1\n",
        "\n",
        "        print(np.shape(sample))\n",
        "        print(np.shape(label))\n",
        "\n",
        "        sample = np.transpose(sample)\n",
        "        label = np.transpose(label)\n",
        "\n",
        "        sample = tf.convert_to_tensor(sample)\n",
        "        label = tf.convert_to_tensor(label)\n",
        "\n",
        "        yield(sample, label)\n",
        "        \n",
        "def create_train_generator():\n",
        "    gen = data_generator('train')\n",
        "    return gen\n",
        "        \n",
        "def create_val_generator():\n",
        "    gen = data_generator('val')\n",
        "    return gen"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZhcL-fY66VE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NEW_MODEL = True\n",
        "\n",
        "if NEW_MODEL:\n",
        "    !rm -r logs/fit/*\n",
        "\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "if NEW_MODEL:\n",
        "    model = build_model()\n",
        "else:\n",
        "    model = tf.keras.models.load_model(\"model/mymodel\")\n",
        "\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_generator(create_train_generator, output_types=(tf.int16, tf.int16), output_shapes=((1000, 501), (1000, 501)))\n",
        "validation_dataset = tf.data.Dataset.from_generator(create_val_generator, output_types=(tf.int16, tf.int16), output_shapes=((1000, 501), (1000, 501)))\n",
        "\n",
        "# for element in dataset:\n",
        "#     sample = np.array(element[0])\n",
        "#     label = np.array(element[1])\n",
        "#     print(np.shape(sample))\n",
        "#     print(np.shape(label))\n",
        "#     # saving images\n",
        "#     path_sample = str(\"./temp/sample0.jpg\")\n",
        "#     sample_to_save = np.stack((sample, sample, sample))\n",
        "#     tf.keras.preprocessing.image.save_img(path_sample, sample_to_save, data_format='channels_first', scale=True)\n",
        "\n",
        "#     break\n",
        "\n",
        "model.fit(train_dataset, epochs=10, shuffle=True, callbacks=[tensorboard_callback], \\\n",
        "          steps_per_epoch=1000, validation_data=validation_dataset, validation_steps=300, verbose=2)\n",
        "\n",
        "model.save('./model/mymodel')\n",
        "print('model saved')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDP50CX6fbM_",
        "colab_type": "text"
      },
      "source": [
        "## **VISUALISATION**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THV1P5I678Qy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !kill 8599"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZYuuj9x5Y_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir logs/fit --host localhost"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6so_2SaUGmHt",
        "colab_type": "text"
      },
      "source": [
        " ## **AUDIO RECONVERSION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPia7BpDe3d5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reshape_data(samples, labels=None):\n",
        "\n",
        "    shapes = np.shape(samples)\n",
        "\n",
        "    samples = np.transpose(samples)\n",
        "    if labels is not None:\n",
        "        labels = np.transpose(labels)\n",
        "\n",
        "    samples = np.reshape(samples, (1, shapes[0]*1000, 501))\n",
        "    if labels is not None:\n",
        "        labels = np.reshape(labels, (1, shapes[0]*1000, 501))\n",
        "\n",
        "    samples = np.squeeze(samples)\n",
        "    if labels is not None:\n",
        "        labels = np.squeeze(labels)\n",
        "\n",
        "    return samples, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcgQig1r1CnL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_and_convert_data(train_mp3_data, add_noise_to_sample=False):\n",
        "\n",
        "    samples = []\n",
        "    im_samples = []\n",
        "    i = 0\n",
        "\n",
        "    for path_to_mp3_file in tqdm(train_mp3_data):\n",
        "\n",
        "        # load mp3 sound to array\n",
        "        loaded_sound = AudioSegment.from_mp3(path_to_mp3_file)\n",
        "        array_sound = np.array(loaded_sound.get_array_of_samples(), np.float64)\n",
        "\n",
        "        len_arr = len(array_sound)\n",
        "\n",
        "        # plt.plot([i for i in range(len(array_sound))], array_sound, 'b')\n",
        "        # plt.show()\n",
        "\n",
        "        # normalize array\n",
        "        mean = np.mean(array_sound, axis=0)\n",
        "        std = np.std(array_sound)\n",
        "        array_sound -= mean\n",
        "        array_sound /= std\n",
        "\n",
        "        if add_noise_to_sample:\n",
        "            array_sound = add_noise(array_sound)\n",
        "\n",
        "        # convert sample to to F_T_space\n",
        "        f, t, array_stft = stft(array_sound, fs=48000, nperseg=1000)\n",
        "        sample_abs_stft = np.abs(array_stft)\n",
        "        sample_im_stft = np.imag(array_stft)\n",
        "\n",
        "        # padding \n",
        "        pad_length = 1000 - np.shape(sample_abs_stft)[1]\n",
        "        sample_abs_stft = np.pad(sample_abs_stft, ((0,0), (0, pad_length)))\n",
        "        sample_im_stft = np.pad(sample_im_stft, ((0,0), (0, pad_length)))\n",
        "\n",
        "        samples.append(sample_abs_stft)\n",
        "        im_samples.append(sample_im_stft)\n",
        "        i+=1\n",
        "\n",
        "    samples = np.array(samples)\n",
        "    im_samples = np.array(im_samples)\n",
        "\n",
        "    return samples, im_samples, mean, std, len_arr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdUwkCvMo_PQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def denoising(samples, imag_samples, mean, std, len_arr):\n",
        "    \n",
        "    # load model\n",
        "    model = tf.keras.models.load_model('./model/mymodel')\n",
        "\n",
        "    # predict\n",
        "    samples, x = reshape_data(samples)\n",
        "    imag_samples, x = reshape_data(imag_samples)\n",
        "    # print(np.shape(samples), np.shape(imag_samples))\n",
        "\n",
        "    denoised_samples = model.predict(samples)\n",
        "    \n",
        "    denoised_samples = np.transpose(denoised_samples)\n",
        "    imag_samples = np.transpose(imag_samples)\n",
        "\n",
        "    print(np.shape(denoised_samples))\n",
        "\n",
        "    plt.pcolormesh(denoised_samples[:len_arr,:])\n",
        "    plt.title('STFT denoised Magnitude')\n",
        "    plt.ylabel('Frequency [Hz]')\n",
        "    plt.xlabel('Time [sec]')\n",
        "    plt.show()\n",
        "\n",
        "    # print(np.shape(denoised_samples))\n",
        "    denoised_stft = denoised_samples + 1j*imag_samples\n",
        "\n",
        "    # convert back to sound from F_T_space\n",
        "    t, desnoised_array_sound = istft(denoised_stft, fs=48000, nperseg=1000)\n",
        "    desnoised_array_sound = np.array(desnoised_array_sound)\n",
        "    desnoised_array_sound *= std\n",
        "    desnoised_array_sound += mean\n",
        "    desnoised_array_sound = np.array(desnoised_array_sound, np.int16)\n",
        "\n",
        "    return desnoised_array_sound\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHbpPOU0yjet",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list_files = [\"./data/original/common_voice_fr_18157595.mp3\"]\n",
        "samples, imag_samples, mean, std, len_arr = load_and_convert_data(list_files, True)\n",
        "\n",
        "denoised_array_sound = denoising(samples, imag_samples, mean, std, len_arr)\n",
        "print(len_arr)\n",
        "denoised_array_sound = denoised_array_sound[:,:len_arr]\n",
        "print(np.shape(denoised_array_sound))\n",
        "\n",
        "\n",
        "plt.plot([i for i in range(len_arr)], desnoised_array_sound, 'r')\n",
        "plt.show()\n",
        "\n",
        "# print(np.shape(denoised_samples))\n",
        "samples, x = reshape_data(samples)\n",
        "samples = np.transpose(samples)\n",
        "samples = samples[:len_arr,:]\n",
        "\n",
        "# print(np.shape(samples))\n",
        "\n",
        "# print(np.shape(denoised_array_sound))\n",
        "\n",
        "plt.pcolormesh(samples)\n",
        "plt.title('STFT sample Magnitude')\n",
        "plt.ylabel('Frequency [Hz]')\n",
        "plt.xlabel('Time [sec]')\n",
        "plt.show()\n",
        "\n",
        "# save reconverted sound to wav\n",
        "path_to_wav_file = './data/denoised/denoised_sound0.wav'\n",
        "write(path_to_wav_file, 48000, denoised_array_sound)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1r_ZimvY7r0j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls model/mymodel/assets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rrtLuCRfpHW",
        "colab_type": "text"
      },
      "source": [
        "## **TEST**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BOZbbKGg64v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load mp3 sound to array\n",
        "mp3_sound = AudioSegment.from_mp3(\"./original/common_voice_fr_18157595.mp3\")\n",
        "array_sound_mp3 = np.array(mp3_sound.get_array_of_samples())\n",
        "\n",
        "# save original to wav\n",
        "path_to_wav_file = './noised/noised_sound0.wav'\n",
        "write(path_to_wav_file, 48000, array_sound_mp3)\n",
        "\n",
        "# save to mp3 from wav\n",
        "mp3_sound_save = AudioSegment.from_wav(path_to_wav_file)\n",
        "mp3_sound_save.export('./original/noised_sound0.mp3', format='mp3')\n",
        "\n",
        "# load wav sound to array\n",
        "samplerate, wav_sound = read(\"./noised/noised_sound0.wav\")\n",
        "array_sound_wav = np.array(wav_sound, np.float64)\n",
        "\n",
        "# # plot\n",
        "# plt.plot([i for i  in range(len(array_sound_wav))], array_sound_wav, 'b')\n",
        "# plt.show()\n",
        "# plt.plot([i for i  in range(len(array_sound_mp3))], array_sound_mp3, 'r')\n",
        "# plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oe1HBz36itI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "outputId": "19f68bc2-8697-4526-e769-464fd11b8010"
      },
      "source": [
        "for i, path_to_mp3_file in enumerate(list_mp3_files[1:2]):\n",
        "\n",
        "    # load mp3 sound to array\n",
        "    loaded_sound = AudioSegment.from_mp3(path_to_mp3_file)\n",
        "    array_sound = np.array(loaded_sound.get_array_of_samples(), np.float64)\n",
        "\n",
        "    # normalize array\n",
        "    mean = np.mean(array_sound, axis=0)\n",
        "    std = np.std(array_sound)\n",
        "    array_sound -= mean\n",
        "    array_sound /= std\n",
        "\n",
        "    # add random noise\n",
        "    max_1 = max(array_sound)\n",
        "    noise = np.random.normal(0, 0.75, len(array_sound))\n",
        "    array_sound_noisy = np.add(noise, array_sound)\n",
        "    max_2 = max(array_sound_noisy)\n",
        "    array_sound_noisy *= max_1/max_2\n",
        "    \n",
        "    # # save original to wav\n",
        "    # array_sound_noisy_to_save = array_sound_noisy * std\n",
        "    # array_sound_noisy_to_save += mean\n",
        "    # array_sound_noisy_to_save = np.array(array_sound_noisy_to_save, np.int16)\n",
        "    # path_to_wav_file = './noised/noised_sound0.wav'\n",
        "    # write(path_to_wav_file, 48000, array_sound_noisy_to_save)\n",
        "\n",
        "    # denoised = np.where(np.sqrt(array_sound_noisy**2-array_sound**2)>array_sound_noisy/3, 0, array_sound_noisy)\n",
        "    # mask = np.where(0<=(array_sound**2)/(noise**2),(array_sound**2)/(noise**2), 0)\n",
        "    # mask = np.where(mask<1,mask, 1)\n",
        "    mask = (array_sound**2)/(noise**2)\n",
        "\n",
        "    denoised = array_sound_noisy * mask\n",
        "\n",
        "    # plot original and noisy\n",
        "    # plt.plot([i for i  in range(len(noise))], noise, 'r')\n",
        "    # plt.plot([i for i  in range(len(array_sound))], array_sound, 'b')\n",
        "    # plt.plot([50000+i for i  in range(1000)], mask[50000:51000], 'r')\n",
        "    plt.plot([i for i  in range(len(denoised))], denoised, 'r')\n",
        "    plt.show()\n",
        "\n",
        "    # save reconverted sound to wav\n",
        "    path_to_wav_file = './denoised/denoised_sound0.wav'\n",
        "    write(path_to_wav_file, 48000, denoised)\n",
        "\n",
        "    # # convert sound to to F_T_space\n",
        "    # f, t, array_stft = stft(array_sound_noisy, fs=48000, nperseg=1000)\n",
        "    # array_abs_stft = np.abs(array_stft)\n",
        "\n",
        "    # plt.pcolormesh(t, f, array_abs_stft)\n",
        "    # plt.title('STFT Magnitude')\n",
        "    # plt.ylabel('Frequency [Hz]')\n",
        "    # plt.xlabel('Time [sec]')\n",
        "    # plt.show()\n",
        "\n",
        "    # # convert back to sound from F_T_space\n",
        "    # t, desnoised_array_sound = istft(array_stft, fs=48000, nperseg=1000)\n",
        "    # desnoised_array_sound = np.array(desnoised_array_sound)\n",
        "    # desnoised_array_sound *= std\n",
        "    # desnoised_array_sound += mean\n",
        "    # desnoised_array_sound = np.array(desnoised_array_sound, np.int16)\n",
        "\n",
        "    # # save reconverted sound to wav\n",
        "    # path_to_wav_file = './denoised/denoised_sound' + str(i) + '.wav'\n",
        "    # write(path_to_wav_file, 48000, desnoised_array_sound)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phNo-Z72foqY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "25d5309e-edcd-4021-e142-f541d1bdfcc5"
      },
      "source": [
        "for path_to_mp3_file in tqdm(train_mp3_data):\n",
        "    # print(i)\n",
        "    a =1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "100%|██████████| 500/500 [00:00<00:00, 310643.16it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zh0r2hNIDaCT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136,
          "referenced_widgets": [
            "94e6fdeca98a4d0b8c7ce52e6162ecd0",
            "774c0af238a24314b0257646698fe490",
            "96a124720fdb42a3a7e025a3329d440a",
            "4df34abfa3eb41c5981bbd460670739a",
            "1918b54b8e624da485e46afc32cff7f2",
            "37ae2d8f98424c71951abecbdb32617e",
            "627ed32a482a4a5dac594dcb0e61186e",
            "cb367e16a13a4bda87e91a76d8100782"
          ]
        },
        "outputId": "29bad297-45cb-4617-c6c3-04b3ccbccf83"
      },
      "source": [
        "\n",
        "samples, labels, mean, std = load_and_convert_data_with_label(list_mp3_files[1:2])\n",
        "\n",
        "print(np.shape(samples))\n",
        "print(np.shape(labels))\n",
        "\n",
        "desnoised_array_stft = samples[0]*labels[0]\n",
        "\n",
        "# convert back to sound from F_T_space\n",
        "t, desnoised_array_sound = istft(desnoised_array_stft, fs=48000, nperseg=1000)\n",
        "desnoised_array_sound = np.array(desnoised_array_sound)\n",
        "desnoised_array_sound *= std\n",
        "desnoised_array_sound += mean\n",
        "desnoised_array_sound = np.array(desnoised_array_sound, np.int16)\n",
        "\n",
        "# save reconverted sound to wav\n",
        "path_to_wav_file = './denoised/denoised_sound0.wav'\n",
        "write(path_to_wav_file, 48000, desnoised_array_sound)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "94e6fdeca98a4d0b8c7ce52e6162ecd0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "(1, 501, 2000)\n",
            "(1, 501, 2000)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:38: RuntimeWarning: invalid value encountered in sqrt\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:38: RuntimeWarning: invalid value encountered in greater\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSQfBJPPGy9K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0a36323b-00f9-4388-983f-c186a18fae00"
      },
      "source": [
        "a = np.array([ 1 + 1j, 1 + 1j, 1 + 1j])\n",
        "b = np.abs(a)\n",
        "c = np.imag(a)\n",
        "d = b + 1j*c\n",
        "print(d)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.41421356+1.j 1.41421356+1.j 1.41421356+1.j]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jc1dlb0R7h8t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def num_conversion(x):\n",
        "    x = np.uint16(x)\n",
        "    result = []\n",
        "    if x < 0:\n",
        "        x = 0\n",
        "    if x >= 65024:\n",
        "        x = 65024\n",
        "    if 0 <= x <= 65024:\n",
        "        x_0 = x - x % 1000\n",
        "        x_1 = x - x_0 - x % 10\n",
        "        result = [x_0//1000, x_1//10]\n",
        "    else:\n",
        "        print(\"error, wrong input\")\n",
        "        print(x)\n",
        "    return result\n",
        "\n",
        "def im_conversion(im):\n",
        "    im = np.array(im, np.int16)\n",
        "    s = np.shape(im)\n",
        "    s = [s[0], s[1], 2]\n",
        "    result = np.zeros(s)\n",
        "    for i in range(s[0]):\n",
        "        for j in range(s[1]):\n",
        "            result[i, j] = num_conversion(im[i, j])\n",
        "    return np.uint16(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_x4tjzGFN28u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def num_conversion_back(x_0, x_1):\n",
        "    number = np.uint16(x_0*1000 + x_1*10) \n",
        "    return number\n",
        "    \n",
        "def im_conversion_back(im_0, im_1):\n",
        "    im_0 = np.array(im_0, np.int16)\n",
        "    im_1 = np.array(im_1, np.int16)\n",
        "    s = np.shape(im_0)\n",
        "    s = [s[0], s[1]]\n",
        "    result = np.zeros(s)\n",
        "    for i in range(s[0]):\n",
        "        for j in range(s[1]):\n",
        "            result[i, j] = num_conversion_back(im_0[i, j], im_1[i, j])\n",
        "    return np.uint16(result)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}