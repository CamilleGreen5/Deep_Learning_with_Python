{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Noise_speech_reduction.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "5rrtLuCRfpHW"
      ],
      "authorship_tag": "ABX9TyN3/qJBZDWkBaUwqCUyPT30",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "47ad93df4f5b47df958f2a158090368f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7e114f29fab54278ae03dc20e0c2e1f7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_01bd65d751a341baa704ac532453099c",
              "IPY_MODEL_6508a13f92cd4526946c995f52a2f004"
            ]
          }
        },
        "7e114f29fab54278ae03dc20e0c2e1f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "01bd65d751a341baa704ac532453099c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fcec4d84c5104aa78fd70a3cfdf356a0",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ab0a499d5da842aeafe43701f412a776"
          }
        },
        "6508a13f92cd4526946c995f52a2f004": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8aa7d91d3c844a24b192b2c43625a998",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/1 [00:00&lt;00:00,  2.61it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b371e7872a884837adb65ed3486cab96"
          }
        },
        "fcec4d84c5104aa78fd70a3cfdf356a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ab0a499d5da842aeafe43701f412a776": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8aa7d91d3c844a24b192b2c43625a998": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b371e7872a884837adb65ed3486cab96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "94e6fdeca98a4d0b8c7ce52e6162ecd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_774c0af238a24314b0257646698fe490",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_96a124720fdb42a3a7e025a3329d440a",
              "IPY_MODEL_4df34abfa3eb41c5981bbd460670739a"
            ]
          }
        },
        "774c0af238a24314b0257646698fe490": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "96a124720fdb42a3a7e025a3329d440a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1918b54b8e624da485e46afc32cff7f2",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_37ae2d8f98424c71951abecbdb32617e"
          }
        },
        "4df34abfa3eb41c5981bbd460670739a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_627ed32a482a4a5dac594dcb0e61186e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/1 [03:10&lt;00:00, 190.56s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cb367e16a13a4bda87e91a76d8100782"
          }
        },
        "1918b54b8e624da485e46afc32cff7f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "37ae2d8f98424c71951abecbdb32617e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "627ed32a482a4a5dac594dcb0e61186e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cb367e16a13a4bda87e91a76d8100782": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CamilleGreen5/Deep_Learning_with_Python/blob/master/Noise_speech_reduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njrINNDksie4",
        "colab_type": "text"
      },
      "source": [
        "INFO :\n",
        "- methode des masks donnent mauvais résultats (avec label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5NDwppQei-Q",
        "colab_type": "text"
      },
      "source": [
        "## **DATA LOADING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfXnXSBj-05D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install pydub"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzPdSF9gRJcb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !wget https://voice-prod-bundler-ee1969a6ce8178826482b88e843c335139bd3fb4.s3.amazonaws.com/cv-corpus-5.1-2020-06-22/fr.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-mU_v6bWlRX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !tar -xf fr.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITu5Puvoakzl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "b2f2c295-d9a8-4a2f-ce6f-efce3a0ca646"
      },
      "source": [
        "# !rm fr.tar.gz\n",
        "# !mkdir original\n",
        "# !mkdir noisy\n",
        "# !mkdir denoised\n",
        "# !mkdir train_data\n",
        "# !mkdir val_data\n",
        "# !mkdir test_data\n",
        "# !mkdir train_data/folder1\n",
        "# !mkdir val_data/folder1\n",
        "# !mkdir test_data/folder1\n",
        "# !cp cv-corpus-5.1-2020-06-22/fr/clips/common_voice_fr_18157595.mp3 ./original"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'fr.tar.gz': No such file or directory\n",
            "mkdir: cannot create directory ‘original’: File exists\n",
            "mkdir: cannot create directory ‘denoised’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9S0MO3jee8d",
        "colab_type": "text"
      },
      "source": [
        "## **FUNCTIONS AND LIBRARIES LOAD**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buYbi1H55f_3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%reload_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7GhHp8oNRF9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import datetime\n",
        "import os\n",
        "from scipy.io.wavfile import read, write\n",
        "from scipy.signal import stft, istft\n",
        "from pydub import AudioSegment\n",
        "from tensorflow.keras import models, layers\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPia7BpDe3d5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reshape_data(samples, labels=None):\n",
        "\n",
        "    shapes = np.shape(samples)\n",
        "\n",
        "    samples = np.transpose(samples)\n",
        "    if labels is not None:\n",
        "        labels = np.transpose(labels)\n",
        "\n",
        "    samples = np.reshape(samples, (1, shapes[0]*2000, 501))\n",
        "    if labels is not None:\n",
        "        labels = np.reshape(labels, (1, shapes[0]*2000, 501))\n",
        "\n",
        "    samples = np.squeeze(samples)\n",
        "    if labels is not None:\n",
        "        labels = np.squeeze(labels)\n",
        "\n",
        "    return samples, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hydHLwi8eyw5",
        "colab_type": "text"
      },
      "source": [
        "## **DATA CONVERSION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2TT4gVTf4sK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_and_convert_data_with_label(train_mp3_data, mode='train'):\n",
        "\n",
        "    i = 0\n",
        "\n",
        "    for path_to_mp3_file in tqdm(train_mp3_data):\n",
        "\n",
        "        # load mp3 sound to array\n",
        "        loaded_sound = AudioSegment.from_mp3(path_to_mp3_file)\n",
        "        array_sound = np.array(loaded_sound.get_array_of_samples(), np.float64)\n",
        "\n",
        "        # normalize array\n",
        "        mean = np.mean(array_sound, axis=0)\n",
        "        std = np.std(array_sound)\n",
        "        array_sound -= mean\n",
        "        array_sound /= std\n",
        "\n",
        "        # convert label to to F_T_space\n",
        "        f, t, array_stft = stft(array_sound, fs=48000, nperseg=1000)\n",
        "        original_abs_stft = np.abs(array_stft)\n",
        "\n",
        "        # padding \n",
        "        pad_length = 2000 - np.shape(original_abs_stft)[1]\n",
        "        original_abs_stft = np.pad(original_abs_stft, ((0,0), (0, pad_length)))\n",
        "\n",
        "        # add random noise\n",
        "        array_sound_noisy = add_noise(array_sound)\n",
        "\n",
        "        # convert sample to to F_T_space\n",
        "        f, t, array_stft = stft(array_sound_noisy, fs=48000, nperseg=1000)\n",
        "        sample_abs_stft = np.abs(array_stft)\n",
        "\n",
        "        # padding \n",
        "        pad_length = 2000 - np.shape(sample_abs_stft)[1]\n",
        "        sample_abs_stft = np.pad(sample_abs_stft, ((0,0), (0, pad_length)))\n",
        "\n",
        "        # convertion to image format\n",
        "        sample_abs_stft = np.stack((sample_abs_stft, original_abs_stft, np.zeros_like(sample_abs_stft)))\n",
        "        # print(np.shape(sample_abs_stft))\n",
        "\n",
        "        # saving images\n",
        "        if mode == 'train':\n",
        "            path_sample = str(\"./train_data/folder1/sample\" + str(i) + \".jpg\")\n",
        "        elif mode == 'val':\n",
        "            path_sample = str(\"./val_data/folder1/sample\" + str(i) + \".jpg\")\n",
        "        elif mode == 'test':\n",
        "            path_sample = str(\"./test_data/folder1/sample\" + str(i) + \".jpg\")\n",
        "        else:\n",
        "            print(\"chose a mode\")\n",
        "        tf.keras.preprocessing.image.save_img(path_sample, sample_abs_stft, data_format='channels_first', scale=True)\n",
        "\n",
        "        # free space\n",
        "        path = train_mp3_data[i]\n",
        "        try:\n",
        "            os.remove(path)\n",
        "        except FileNotFoundError:\n",
        "            continue\n",
        "\n",
        "        i+=1\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOdsq0ea13dj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_noise(array_sound):\n",
        "          \n",
        "    max_1 = max(array_sound)\n",
        "    noise = np.random.normal(0, 0.75, len(array_sound))\n",
        "    array_sound_noisy = np.add(noise, array_sound)\n",
        "    max_2 = max(array_sound_noisy)\n",
        "    array_sound_noisy *= max_1/max_2\n",
        "\n",
        "    return array_sound_noisy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1kmyRNo_wrO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !rm -r train_data\n",
        "# !rm -r val_data\n",
        "# !rm -r test_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOvohzPDeb9U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "54772227-9e8e-40e9-ba42-28ecca8bd3a9"
      },
      "source": [
        "list_mp3_files = glob.glob(\"./cv-corpus-5.1-2020-06-22/fr/clips/*.mp3\")\n",
        "print(len(list_mp3_files))\n",
        "\n",
        "train_mp3_data = list_mp3_files[5000:10000]\n",
        "val_mp3_data = list_mp3_files[10000:12000]\n",
        "test_mp3_data = list_mp3_files[12000:14000]"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "443292\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCwxQ3Z6j-FI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "load_and_convert_data_with_label(train_mp3_data, 'train')\n",
        "load_and_convert_data_with_label(val_mp3_data, 'val')\n",
        "load_and_convert_data_with_label(test_mp3_data, 'test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsBC7dTbfCcD",
        "colab_type": "text"
      },
      "source": [
        "## **MODEL FITING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0f500K0Izlr6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -r logs/fit/*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5YPnEf4AS7m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model():\n",
        "\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Dense(1000, activation='re lu', input_shape=(501,)))\n",
        "    model.add(layers.Dense(1000, activation='relu'))\n",
        "    model.add(layers.Dense(501))\n",
        "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7JeMASisCLN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_generator(mode='train'):\n",
        "\n",
        "    img_gen = tf.keras.preprocessing.image.ImageDataGenerator()\n",
        "    if mode == 'train':\n",
        "        samples_and_labels = img_gen.flow_from_directory(\"./train_data/\", class_mode=None, target_size=(501, 2000), batch_size=1)\n",
        "    elif mode == 'val':\n",
        "        samples_and_labels = img_gen.flow_from_directory(\"./val_data/\", class_mode=None, target_size=(501, 2000), batch_size=1)\n",
        "    elif mode == 'test':\n",
        "        samples_and_labels = img_gen.flow_from_directory(\"./test_data/\", class_mode=None, target_size=(501, 2000), batch_size=1)  \n",
        "    else:\n",
        "        print(\"chose a mode\")\n",
        "\n",
        "    for sample_and_label in samples_and_labels:\n",
        "        sample_and_label = np.array(sample_and_label)\n",
        "        sample = sample_and_label[:,:,:,0]\n",
        "        label = sample_and_label[:,:,:,1]\n",
        "        sample = np.transpose(np.squeeze(sample))\n",
        "        label = np.transpose(np.squeeze(label))\n",
        "        sample = tf.convert_to_tensor(sample)\n",
        "        label = tf.convert_to_tensor(label)\n",
        "        yield(sample, label)\n",
        "        \n",
        "def create_train_generator():\n",
        "    gen = data_generator('train')\n",
        "    return gen\n",
        "        \n",
        "def create_val_generator():\n",
        "    gen = data_generator('val')\n",
        "    return gen"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZhcL-fY66VE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "outputId": "18597538-595b-4578-f19c-8c7f7f402b73"
      },
      "source": [
        "NEW_MODEL = True\n",
        "\n",
        "if NEW_MODEL:\n",
        "    !rm -r logs/fit/*\n",
        "\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "if NEW_MODEL:\n",
        "    model = build_model()\n",
        "else:\n",
        "    model = tf.keras.models.load_model(\"model/mymodel\")\n",
        "\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_generator(create_train_generator, output_types=(tf.int16, tf.int16), output_shapes=((2000, 501), (2000, 501)))\n",
        "validation_dataset = tf.data.Dataset.from_generator(create_val_generator, output_types=(tf.int16, tf.int16), output_shapes=((2000, 501), (2000, 501)))\n",
        "\n",
        "# for element in dataset:\n",
        "#     sample = np.array(element[0])\n",
        "#     label = np.array(element[1])\n",
        "#     print(np.shape(sample))\n",
        "#     print(np.shape(label))\n",
        "#     # saving images\n",
        "#     path_sample = str(\"./temp/sample0.jpg\")\n",
        "#     sample_to_save = np.stack((sample, sample, sample))\n",
        "#     tf.keras.preprocessing.image.save_img(path_sample, sample_to_save, data_format='channels_first', scale=True)\n",
        "\n",
        "#     break\n",
        "\n",
        "model.fit(train_dataset, epochs=50, shuffle=True, callbacks=[tensorboard_callback], \\\n",
        "          steps_per_epoch=1000, validation_data=validation_dataset, validation_steps=100, verbose=2)\n",
        "\n",
        "model.save('./model/mymodel')\n",
        "print('model saved')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "Found 1000 images belonging to 1 classes.\n",
            "Found 200 images belonging to 1 classes.\n",
            "100/100 - 6s - loss: 2.1582 - mae: 0.2765 - val_loss: 2.6455 - val_mae: 0.3105\n",
            "Epoch 2/50\n",
            "Found 200 images belonging to 1 classes.\n",
            "100/100 - 6s - loss: 1.3139 - mae: 0.2513 - val_loss: 1.7651 - val_mae: 0.2412\n",
            "Epoch 3/50\n",
            "Found 200 images belonging to 1 classes.\n",
            "100/100 - 6s - loss: 1.1123 - mae: 0.2260 - val_loss: 0.7026 - val_mae: 0.1971\n",
            "Epoch 4/50\n",
            "Found 200 images belonging to 1 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-109-96ab25bb1efa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m#     break\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensorboard_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./model/mymodel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1131\u001b[0m               \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m               return_dict=True)\n\u001b[0m\u001b[1;32m   1134\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1377\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TraceContext'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1379\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1380\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDP50CX6fbM_",
        "colab_type": "text"
      },
      "source": [
        "## **VISUALISATION AND TEST**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THV1P5I678Qy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kill 8599"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZYuuj9x5Y_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir logs/fit --host localhost"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcgQig1r1CnL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_and_convert_data(train_mp3_data, add_noise_to_sample=False):\n",
        "\n",
        "    samples = []\n",
        "    im_samples = []\n",
        "    i = 0\n",
        "\n",
        "    for path_to_mp3_file in tqdm(train_mp3_data):\n",
        "\n",
        "        # load mp3 sound to array\n",
        "        loaded_sound = AudioSegment.from_mp3(path_to_mp3_file)\n",
        "        array_sound = np.array(loaded_sound.get_array_of_samples(), np.float64)\n",
        "\n",
        "        # plt.plot([i for i in range(len(array_sound))], array_sound, 'b')\n",
        "        # plt.show()\n",
        "\n",
        "        # normalize array\n",
        "        mean = np.mean(array_sound, axis=0)\n",
        "        std = np.std(array_sound)\n",
        "        array_sound -= mean\n",
        "        array_sound /= std\n",
        "\n",
        "        if add_noise_to_sample:\n",
        "            array_sound = add_noise(array_sound)\n",
        "\n",
        "        # convert sample to to F_T_space\n",
        "        f, t, array_stft = stft(array_sound, fs=48000, nperseg=1000)\n",
        "        sample_abs_stft = np.abs(array_stft)\n",
        "        sample_im_stft = np.imag(array_stft)\n",
        "\n",
        "        # padding \n",
        "        pad_length = 2000 - np.shape(sample_abs_stft)[1]\n",
        "        sample_abs_stft = np.pad(sample_abs_stft, ((0,0), (0, pad_length)))\n",
        "        sample_im_stft = np.pad(sample_im_stft, ((0,0), (0, pad_length)))\n",
        "\n",
        "        samples.append(sample_abs_stft)\n",
        "        im_samples.append(sample_im_stft)\n",
        "        i+=1\n",
        "\n",
        "    samples = np.array(samples)\n",
        "    im_samples = np.array(im_samples)\n",
        "\n",
        "    return samples, im_samples, mean, std"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdUwkCvMo_PQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def denoising(samples, imag_samples, mean, std):\n",
        "    \n",
        "    # load model\n",
        "    model = tf.keras.models.load_model('./model/mymodel')\n",
        "\n",
        "    # predict\n",
        "    samples, x = reshape_data(samples)\n",
        "    imag_samples, x = reshape_data(imag_samples)\n",
        "    # print(np.shape(samples), np.shape(imag_samples))\n",
        "\n",
        "    denoised_samples = model.predict(samples)\n",
        "    # print(np.shape(denoised_samples))\n",
        "    denoised_stft = denoised_samples + 1j*imag_samples\n",
        "\n",
        "    # convert back to sound from F_T_space\n",
        "    t, desnoised_array_sound = istft(denoised_stft, fs=48000, nperseg=1000)\n",
        "    desnoised_array_sound = np.array(desnoised_array_sound)\n",
        "    desnoised_array_sound *= std\n",
        "    desnoised_array_sound += mean\n",
        "    desnoised_array_sound = np.array(desnoised_array_sound, np.int16)\n",
        "\n",
        "    # plt.plot([i for i in range(len(desnoised_array_sound))], desnoised_array_sound, 'r')\n",
        "    # plt.show()\n",
        "\n",
        "    return desnoised_array_sound\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHbpPOU0yjet",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332,
          "referenced_widgets": [
            "47ad93df4f5b47df958f2a158090368f",
            "7e114f29fab54278ae03dc20e0c2e1f7",
            "01bd65d751a341baa704ac532453099c",
            "6508a13f92cd4526946c995f52a2f004",
            "fcec4d84c5104aa78fd70a3cfdf356a0",
            "ab0a499d5da842aeafe43701f412a776",
            "8aa7d91d3c844a24b192b2c43625a998",
            "b371e7872a884837adb65ed3486cab96"
          ]
        },
        "outputId": "0c2fd22d-43b8-4e6c-ab6c-214f5f7bff91"
      },
      "source": [
        "list_files = [\"./original/common_voice_fr_18157595.mp3\"]\n",
        "samples, imag_samples, mean, std = load_and_convert_data(list_files, True)\n",
        "\n",
        "denoised_array_sound = denoising(samples, imag_samples, mean, std)\n",
        "\n",
        "# print(np.shape(denoised_array_sound))\n",
        "\n",
        "# save reconverted sound to wav\n",
        "path_to_wav_file = './denoised/denoised_sound0.wav'\n",
        "write(path_to_wav_file, 48000, denoised_array_sound)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "47ad93df4f5b47df958f2a158090368f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "(2000, 501)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rrtLuCRfpHW",
        "colab_type": "text"
      },
      "source": [
        "## **TEST**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BOZbbKGg64v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load mp3 sound to array\n",
        "mp3_sound = AudioSegment.from_mp3(\"./original/common_voice_fr_18157595.mp3\")\n",
        "array_sound_mp3 = np.array(mp3_sound.get_array_of_samples())\n",
        "\n",
        "# save original to wav\n",
        "path_to_wav_file = './noised/noised_sound0.wav'\n",
        "write(path_to_wav_file, 48000, array_sound_mp3)\n",
        "\n",
        "# save to mp3 from wav\n",
        "mp3_sound_save = AudioSegment.from_wav(path_to_wav_file)\n",
        "mp3_sound_save.export('./original/noised_sound0.mp3', format='mp3')\n",
        "\n",
        "# load wav sound to array\n",
        "samplerate, wav_sound = read(\"./noised/noised_sound0.wav\")\n",
        "array_sound_wav = np.array(wav_sound, np.float64)\n",
        "\n",
        "# # plot\n",
        "# plt.plot([i for i  in range(len(array_sound_wav))], array_sound_wav, 'b')\n",
        "# plt.show()\n",
        "# plt.plot([i for i  in range(len(array_sound_mp3))], array_sound_mp3, 'r')\n",
        "# plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oe1HBz36itI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "outputId": "19f68bc2-8697-4526-e769-464fd11b8010"
      },
      "source": [
        "for i, path_to_mp3_file in enumerate(list_mp3_files[1:2]):\n",
        "\n",
        "    # load mp3 sound to array\n",
        "    loaded_sound = AudioSegment.from_mp3(path_to_mp3_file)\n",
        "    array_sound = np.array(loaded_sound.get_array_of_samples(), np.float64)\n",
        "\n",
        "    # normalize array\n",
        "    mean = np.mean(array_sound, axis=0)\n",
        "    std = np.std(array_sound)\n",
        "    array_sound -= mean\n",
        "    array_sound /= std\n",
        "\n",
        "    # add random noise\n",
        "    max_1 = max(array_sound)\n",
        "    noise = np.random.normal(0, 0.75, len(array_sound))\n",
        "    array_sound_noisy = np.add(noise, array_sound)\n",
        "    max_2 = max(array_sound_noisy)\n",
        "    array_sound_noisy *= max_1/max_2\n",
        "    \n",
        "    # # save original to wav\n",
        "    # array_sound_noisy_to_save = array_sound_noisy * std\n",
        "    # array_sound_noisy_to_save += mean\n",
        "    # array_sound_noisy_to_save = np.array(array_sound_noisy_to_save, np.int16)\n",
        "    # path_to_wav_file = './noised/noised_sound0.wav'\n",
        "    # write(path_to_wav_file, 48000, array_sound_noisy_to_save)\n",
        "\n",
        "    # denoised = np.where(np.sqrt(array_sound_noisy**2-array_sound**2)>array_sound_noisy/3, 0, array_sound_noisy)\n",
        "    # mask = np.where(0<=(array_sound**2)/(noise**2),(array_sound**2)/(noise**2), 0)\n",
        "    # mask = np.where(mask<1,mask, 1)\n",
        "    mask = (array_sound**2)/(noise**2)\n",
        "\n",
        "    denoised = array_sound_noisy * mask\n",
        "\n",
        "    # plot original and noisy\n",
        "    # plt.plot([i for i  in range(len(noise))], noise, 'r')\n",
        "    # plt.plot([i for i  in range(len(array_sound))], array_sound, 'b')\n",
        "    # plt.plot([50000+i for i  in range(1000)], mask[50000:51000], 'r')\n",
        "    plt.plot([i for i  in range(len(denoised))], denoised, 'r')\n",
        "    plt.show()\n",
        "\n",
        "    # save reconverted sound to wav\n",
        "    path_to_wav_file = './denoised/denoised_sound0.wav'\n",
        "    write(path_to_wav_file, 48000, denoised)\n",
        "\n",
        "    # # convert sound to to F_T_space\n",
        "    # f, t, array_stft = stft(array_sound_noisy, fs=48000, nperseg=1000)\n",
        "    # array_abs_stft = np.abs(array_stft)\n",
        "\n",
        "    # plt.pcolormesh(t, f, array_abs_stft)\n",
        "    # plt.title('STFT Magnitude')\n",
        "    # plt.ylabel('Frequency [Hz]')\n",
        "    # plt.xlabel('Time [sec]')\n",
        "    # plt.show()\n",
        "\n",
        "    # # convert back to sound from F_T_space\n",
        "    # t, desnoised_array_sound = istft(array_stft, fs=48000, nperseg=1000)\n",
        "    # desnoised_array_sound = np.array(desnoised_array_sound)\n",
        "    # desnoised_array_sound *= std\n",
        "    # desnoised_array_sound += mean\n",
        "    # desnoised_array_sound = np.array(desnoised_array_sound, np.int16)\n",
        "\n",
        "    # # save reconverted sound to wav\n",
        "    # path_to_wav_file = './denoised/denoised_sound' + str(i) + '.wav'\n",
        "    # write(path_to_wav_file, 48000, desnoised_array_sound)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phNo-Z72foqY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "25d5309e-edcd-4021-e142-f541d1bdfcc5"
      },
      "source": [
        "for path_to_mp3_file in tqdm(train_mp3_data):\n",
        "    # print(i)\n",
        "    a =1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "100%|██████████| 500/500 [00:00<00:00, 310643.16it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zh0r2hNIDaCT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136,
          "referenced_widgets": [
            "94e6fdeca98a4d0b8c7ce52e6162ecd0",
            "774c0af238a24314b0257646698fe490",
            "96a124720fdb42a3a7e025a3329d440a",
            "4df34abfa3eb41c5981bbd460670739a",
            "1918b54b8e624da485e46afc32cff7f2",
            "37ae2d8f98424c71951abecbdb32617e",
            "627ed32a482a4a5dac594dcb0e61186e",
            "cb367e16a13a4bda87e91a76d8100782"
          ]
        },
        "outputId": "29bad297-45cb-4617-c6c3-04b3ccbccf83"
      },
      "source": [
        "\n",
        "samples, labels, mean, std = load_and_convert_data_with_label(list_mp3_files[1:2])\n",
        "\n",
        "print(np.shape(samples))\n",
        "print(np.shape(labels))\n",
        "\n",
        "desnoised_array_stft = samples[0]*labels[0]\n",
        "\n",
        "# convert back to sound from F_T_space\n",
        "t, desnoised_array_sound = istft(desnoised_array_stft, fs=48000, nperseg=1000)\n",
        "desnoised_array_sound = np.array(desnoised_array_sound)\n",
        "desnoised_array_sound *= std\n",
        "desnoised_array_sound += mean\n",
        "desnoised_array_sound = np.array(desnoised_array_sound, np.int16)\n",
        "\n",
        "# save reconverted sound to wav\n",
        "path_to_wav_file = './denoised/denoised_sound0.wav'\n",
        "write(path_to_wav_file, 48000, desnoised_array_sound)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "94e6fdeca98a4d0b8c7ce52e6162ecd0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "(1, 501, 2000)\n",
            "(1, 501, 2000)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:38: RuntimeWarning: invalid value encountered in sqrt\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:38: RuntimeWarning: invalid value encountered in greater\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSQfBJPPGy9K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0a36323b-00f9-4388-983f-c186a18fae00"
      },
      "source": [
        "a = np.array([ 1 + 1j, 1 + 1j, 1 + 1j])\n",
        "b = np.abs(a)\n",
        "c = np.imag(a)\n",
        "d = b + 1j*c\n",
        "print(d)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.41421356+1.j 1.41421356+1.j 1.41421356+1.j]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}